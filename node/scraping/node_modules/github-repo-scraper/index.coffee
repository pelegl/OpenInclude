###
  Config
###
qs               = require 'querystring' 
colors           = require 'colors'
_                = require 'underscore'
async            = require 'async'

colors.setTheme
  silly   : 'rainbow'
  input   : 'grey'
  verbose : 'cyan'
  prompt  : 'grey'
  info    : 'green'
  data    : 'grey'
  help    : 'cyan'
  warn    : 'yellow'
  debug   : 'blue'
  error   : 'red'
  
###
  Url config
###
Url = "https://github.com/search?"
DefaultQuery =
  query:
    q   : "stars:>100"
    type: "Repositories"
    s   :  "stars"
  options:
    main: true   
###
  Scraping class
###
Spooky = require 'spooky'

###
  Start spookie func
###
newSpooky = (proxy_list, callback)->
  index = Math.floor(Math.random()*proxy_list.length)
  proxy = proxy_list[index]
  proxy = "#{proxy.ip}:#{proxy.port}"    
  
  #console.log "Starting spooky"
  ports = (i for i in [8080..8081])
  async.map ports, (port, async_callback)=>
    spooky = new Spooky {
      casper:
        logLevel      : "debug"
        verbose       : true
        clientScripts : ["components/jquery/jquery.min.js"]
        loadImages    :  false
      child: 
        transport: "http"
        port     : port
    },(err)=>
      
      spooky.on 'error', (e)->
        console.error e 
      
      spooky.on 'console', (line)-> 
        console.log line
                                               
      spooky.on 'remote.message', (msg)->
        @echo 'remote message caught: '.debug + msg 
        
      async_callback err, spooky
  ,callback  
  
###
  Start the job
###
spookie_start = (proxy_list, callback)-> 
  newSpooky proxy_list, (err, browsers)->  
    ###
      Reporting
    ###
    console.log err.error if err?    
    
    [spooky] = browsers               
    
    total_browsers  = browsers.length-1
    next_browser    = 1
    
    ###
      Not working - try later
    ###
    spooky.on 'start.flow', (task)->
      #console.log "Starting new flow ".debug, task
      c = browsers[next_browser++]      
      c.start()
      c.then ->
        @echo "Starting parallel process"
      c.run [{DefaultQuery: task, Url}, flow]
      
      next_browser = 0 if next_browser > total_browsers
              
    ###
      Flow control
    ###
    spooky.start()
    spooky.then ->
      @echo "Starting scraping session"
    
    flow = ()->   
      casper = @   
      ###
        Setup jobs
      ###
      agents           = require 'user-agents'
      qs               = require 'querystring'
      _                = require 'underscore/underscore'
      
      currentSuite = 0    
      suites       = []      
      
      set_headers = ->
        headers = 
            "accept"         : "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
            "user-agent"     : agents.random()
            "accept-language": "ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3"
            "cache-control"  : "max-age=0"
            "connection"     : "keep-alive"
            "accept-charset" : "utf-8,windows-1251;q=0.7,*;q=0.3"  
        headers
      
      for_main_suite = (current_page, total_pages) ->        
        for i in [(current_page+1)..total_pages]
          req = _.extend {}, DefaultQuery
          req.query.p = i
          req.options =
            main: false
            lastPage : total_pages                             
          
          add_suite req
          #if i is total_pages          
          #  add_suite req
          #else
          #  @emit "start.flow", req
      
      for_child_suite = (current_page, total_pages) ->
        if current_page is total_pages
          minimum_amount_of_stars = parseInt @evaluate -> $(".repolist > li:last .stargazers a").text()
          if minimum_amount_of_stars > 100 
            req = _.extend {}, DefaultQuery
            req.query.q = "stars:100..#{minimum_amount_of_stars}"
            delete req.query.p                      
            add_suite req
      
      modulesCache = {}             
      add_suite = (query)->      
        query = JSON.stringify query        
        suites.push ->                                
          q = JSON.parse query
          request = Url + qs.stringify q.query
          @start request, { headers: set_headers() }
          @then ->
            {main, lastPage} = q.options            
            total_pages   = if main is true then parseInt @evaluate -> $(".pagination .next_page").prev().text() else lastPage
            current_page  = parseInt @evaluate -> $(".pagination .current").text()
            if main is true
              for_main_suite current_page, total_pages   
            else
              for_child_suite.call @, current_page, total_pages
              
            @echo "#{current_page}/#{total_pages}"
          @then ->
            repos = @evaluate ->
              #console.log "Started evaluate"
              modules = {}
              $(".repolist > li").each (index, element)->                               
                $this = $(this)                                                
                fullName  = $this.children("h3").find("a").text()                                
                name      = fullName.split("/")                
                stats     = $(".repo-stats", $this)                
                pushed    = $this.find(".updated-at time").attr("datetime")
                                
                $el  = $("li", stats).eq(0)
                lang = if $el.attr("class") then "Text" else $el.text()
                                
                repo = 
                  module_name : name[1]
                  owner       : name[0]
                  is_a_fork   : false
                  username    : name[0]
                  language    : lang
                  watchers    : parseInt $(".stargazers a", stats).text()
                  forks       : $(".forks a", stats).text()
                  description : $.trim $this.find(".description").text()
                  pushed_at   : new Date(pushed)
                                
                modules[fullName] = repo
              modules
                          
            @emit "module.scraped", repos
                              
      add_suite DefaultQuery
      
      check = ->                      
        if suites[currentSuite]
          console.log "started #{currentSuite} check"
          suites[currentSuite].call casper
          currentSuite++
          casper.run check
        else
          casper.echo "All done."
          casper.exit()
                                     
      check()
                              
    spooky.run [{DefaultQuery, Url}, flow]
    
    
        
    spooky.on 'module.scraped', (repos)=>
      callback null, repos
    
    spooky.on 'exit', ->
      callback null, "Suite completed", true

module.exports = spookie_start